<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="一个灵活的咸鱼，中宇云网欢迎您"><title>Nic的鱼塘，一条小小的咸鱼 | 一个灵活的咸</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Nic的鱼塘，一条小小的咸鱼</h1><a id="logo" href="/.">Nic的鱼塘，一条小小的咸鱼</a><p class="description">一个灵活的咸</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2018/05/08/2018-05-08-lonely-1/">成为独立开发者</a></h1><div class="post-meta">2018-05-08</div><div class="post-content"><p>这周，我1个上班族，带着对梦想的追求离开了稳定的环境，成为了1个独立开发者。</p>
<p>作为1个独立开发者，自己养活自己可不那么容易，市场上转悠了一圈，落地项目还是逃不开微信公众号、ios和安卓大环境，作为一个后端开发的我，对这些前端落地界面，还是有着不断的挑战，同时，我可能需要一些落地的app项目来包装自己，所以一头扎进了移动端开发的坑。</p></div><p class="readmore"><a href="/2018/05/08/2018-05-08-lonely-1/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/11/13/2017-11-13-it/">go for it</a></h1><div class="post-meta">2017-11-13</div><div class="post-content"><p><code>为什么要创造一门编程语言</code></p>
<ul>
<li>C/C++ 的发展速度无法跟上计算机发展的脚步，十多年来也没有出现一门与时代相符的主流系统编程语言，因此人们需要一门新的系统编程语言来弥补这个空缺，尤其是在计算机信息时代。</li>
<li>对比计算机性能的提升，软件开发领域不被认为发展地足够快或者比硬件发展更加成功（有许多项目均以失败告终），同时应用程序的体积始终在不断地扩大，这就迫切地需要一门具备更高层次概念的低级语言来突破现状。</li></div><p class="readmore"><a href="/2017/11/13/2017-11-13-it/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/09/09/2017-09-09-DNN-iris/">DNN-iris</a></h1><div class="post-meta">2017-09-09</div><div class="post-content"><p>base on python2</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data sets</span></span><br><span class="line">IRIS_TRAINING = <span class="string">"iris_training.csv"</span></span><br><span class="line">IRIS_TRAINING_URL = <span class="string">"http://download.tensorflow.org/data/iris_training.csv"</span></span><br><span class="line"></span><br><span class="line">IRIS_TEST = <span class="string">"iris_test.csv"</span></span><br><span class="line">IRIS_TEST_URL = <span class="string">"http://download.tensorflow.org/data/iris_test.csv"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># If the training and test sets aren't stored locally, download them.</span></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(IRIS_TRAINING):</span><br><span class="line">    raw = urllib.urlopen(IRIS_TRAINING_URL).read()</span><br><span class="line">    <span class="keyword">with</span> open(IRIS_TRAINING, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">      f.write(raw)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(IRIS_TEST):</span><br><span class="line">    raw = urllib.urlopen(IRIS_TEST_URL).read()</span><br><span class="line">    <span class="keyword">with</span> open(IRIS_TEST, <span class="string">"w"</span>) <span class="keyword">as</span> f:</span><br><span class="line">      f.write(raw)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Load datasets.</span></span><br><span class="line">  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">      filename=IRIS_TRAINING,</span><br><span class="line">      target_dtype=np.int,</span><br><span class="line">      features_dtype=np.float32)</span><br><span class="line">  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</span><br><span class="line">      filename=IRIS_TEST,</span><br><span class="line">      target_dtype=np.int,</span><br><span class="line">      features_dtype=np.float32)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Specify that all features have real-value data</span></span><br><span class="line">  feature_columns = [tf.feature_column.numeric_column(<span class="string">"x"</span>, shape=[<span class="number">4</span>])]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></span><br><span class="line">  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,</span><br><span class="line">                                          hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</span><br><span class="line">                                          n_classes=<span class="number">3</span>,</span><br><span class="line">                                          model_dir=<span class="string">"/tmp/iris_model"</span>)</span><br><span class="line">  <span class="comment"># Define the training inputs</span></span><br><span class="line">  train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">      x=&#123;<span class="string">"x"</span>: np.array(training_set.data)&#125;,</span><br><span class="line">      y=np.array(training_set.target),</span><br><span class="line">      num_epochs=<span class="keyword">None</span>,</span><br><span class="line">      shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Train model.</span></span><br><span class="line">  classifier.train(input_fn=train_input_fn, steps=<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Define the test inputs</span></span><br><span class="line">  test_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">      x=&#123;<span class="string">"x"</span>: np.array(test_set.data)&#125;,</span><br><span class="line">      y=np.array(test_set.target),</span><br><span class="line">      num_epochs=<span class="number">1</span>,</span><br><span class="line">      shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Evaluate accuracy.</span></span><br><span class="line">  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[<span class="string">"accuracy"</span>]</span><br><span class="line"></span><br><span class="line">  print(<span class="string">"\nTest Accuracy: &#123;0:f&#125;\n"</span>.format(accuracy_score))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Classify two new flower samples.</span></span><br><span class="line">  new_samples = np.array(</span><br><span class="line">      [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>],</span><br><span class="line">       [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], dtype=np.float32)</span><br><span class="line">  predict_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">      x=&#123;<span class="string">"x"</span>: new_samples&#125;,</span><br><span class="line">      num_epochs=<span class="number">1</span>,</span><br><span class="line">      shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">  predictions = list(classifier.predict(input_fn=predict_input_fn))</span><br><span class="line">  predicted_classes = [p[<span class="string">"classes"</span>] <span class="keyword">for</span> p <span class="keyword">in</span> predictions]</span><br><span class="line"></span><br><span class="line">  print(</span><br><span class="line">      <span class="string">"New Samples, Class Predictions:    &#123;&#125;\n"</span></span><br><span class="line">      .format(predicted_classes))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2017/09/09/2017-09-09-DNN-iris/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/04/05/2017-04-05-LSTM/">LSTM</a></h1><div class="post-meta">2017-04-05</div><div class="post-content"><p>推荐理论blog: <a href="http://www.csdn.net/article/2015-11-25/2826323" target="_blank" rel="noopener">http://www.csdn.net/article/2015-11-25/2826323</a></p></div><p class="readmore"><a href="/2017/04/05/2017-04-05-LSTM/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/04/02/2017-04-02-tensorflow-cnn/">tensorflow-cnn</a></h1><div class="post-meta">2017-04-02</div><div class="post-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, w)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, w, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">'mnist'</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">    sess = tf.InteractiveSession()</span><br><span class="line"></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">    x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    w_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</span><br><span class="line">    b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line">    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)</span><br><span class="line">    h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line">    w_conv2 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">64</span>])</span><br><span class="line">    b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line">    h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2)+ b_conv2)</span><br><span class="line">    h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line">    w_fc1 = weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>,<span class="number">1024</span>])</span><br><span class="line">    b_fc1 = bias_variable([<span class="number">1024</span>])</span><br><span class="line"></span><br><span class="line">    h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line">    keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line"></span><br><span class="line">    w_fc2 = weight_variable([<span class="number">1024</span>,<span class="number">10</span>])</span><br><span class="line">    b_fc2 = bias_variable([<span class="number">10</span>])</span><br><span class="line">    y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)</span><br><span class="line"></span><br><span class="line">    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">    train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">        batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> ==<span class="number">0</span>:</span><br><span class="line">            train_accuracy = accuracy.eval(feed_dict=&#123;x:batch[<span class="number">0</span>], y_:batch[<span class="number">1</span>], keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">            print(<span class="string">"step %d, training accuracy %g"</span>%(i, train_accuracy))</span><br><span class="line">        train_step.run(feed_dict=&#123;x:batch[<span class="number">0</span>], y_:batch[<span class="number">1</span>], keep_prob:<span class="number">0.5</span>&#125;)</span><br><span class="line">    print(<span class="string">"test accuracy %g"</span>%accuracy.eval(feed_dict=&#123;x:mnist.test.images, y_:mnist.test.labels, keep_prob:<span class="number">1.0</span>&#125;))</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2017/04/02/2017-04-02-tensorflow-cnn/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/03/27/2017-03-27-mnist-single-layer/">mnist单隐层的神经网络</a></h1><div class="post-meta">2017-03-27</div><div class="post-content"><p>#mnist单隐层的神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'mnist'</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">sess =  tf.InteractiveSession()</span><br><span class="line">in_units = <span class="number">784</span>   <span class="comment"># 28 * 28</span></span><br><span class="line">h1_units = <span class="number">300</span> <span class="comment"># hidden nodes</span></span><br><span class="line">w1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([h1_units]))</span><br><span class="line">w2 = tf.Variable(tf.zeros([h1_units, <span class="number">10</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 forwawrd part</span></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, in_units])</span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">hidden1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line">hidden1_drop = tf.nn.dropout(hidden1, keep_prob)</span><br><span class="line">y = tf.nn.softmax(tf.matmul(hidden1_drop, w2) + b2)</span><br><span class="line"><span class="comment"># 2 loss and optimizer</span></span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.AdagradOptimizer(<span class="number">0.3</span>).minimize(cross_entropy)</span><br><span class="line"><span class="comment"># 3 run</span></span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    train_step.run(&#123;x: batch_xs, y_:batch_ys, keep_prob: <span class="number">0.75</span>&#125;)</span><br><span class="line"><span class="comment"># 4 test</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">print(accuracy.eval(&#123;x:mnist.test.images, y_:mnist.test.labels, keep_prob:<span class="number">3.0</span>&#125;))  <span class="comment"># 0.979</span></span><br><span class="line">最后准确率在<span class="number">0.979</span></span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2017/03/27/2017-03-27-mnist-single-layer/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/03/26/2017-03-26-tensorflow-autoencoder/">tensorflow-autoencoder</a></h1><div class="post-meta">2017-03-26</div><div class="post-content"><h1 id="加性高斯噪声自编码器"><a href="#加性高斯噪声自编码器" class="headerlink" title="加性高斯噪声自编码器"></a>加性高斯噪声自编码器</h1><hr>
<p>先上代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sklearn.preprocessing <span class="keyword">as</span> prep</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier_init</span><span class="params">(fan_in, fan_out, constant=<span class="number">1</span>)</span>:</span></span><br><span class="line">    high = constant * np.sqrt(<span class="number">6.0</span> / (fan_in + fan_out))</span><br><span class="line">    low = -high</span><br><span class="line">    <span class="keyword">return</span> tf.random_uniform((fan_in, fan_out), minval=low, maxval=high, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standard_scale</span><span class="params">(x_train, x_test)</span>:</span></span><br><span class="line">    preprocessor = prep.StandardScaler().fit(x_train)</span><br><span class="line">    x_train = preprocessor.transform(x_train)</span><br><span class="line">    x_test = preprocessor.transform(x_test)</span><br><span class="line">    <span class="keyword">return</span> x_train, x_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_random_block_from_data</span><span class="params">(data, batch_size)</span>:</span></span><br><span class="line">    start_index = np.random.randint(<span class="number">0</span>, len(data) - batch_size)</span><br><span class="line">    <span class="keyword">return</span> data[start_index:(start_index + batch_size)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdditiveGaussianNoiseAutoenvoder</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_input, n_hidden, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer<span class="params">()</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 scale=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        self.n_input = n_input</span><br><span class="line">        self.n_hidden = n_hidden</span><br><span class="line">        self.transfer = transfer_function</span><br><span class="line">        self.scale = tf.placeholder(tf.float32)</span><br><span class="line">        self.training_scale = scale</span><br><span class="line">        self.weights = self._initialize_weights()</span><br><span class="line"></span><br><span class="line">        self.x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, self.n_input])</span><br><span class="line">        <span class="comment"># x * w + b</span></span><br><span class="line">        self.hidden = self.transfer(</span><br><span class="line">            tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)), self.weights[<span class="string">'w1'</span>]), self.weights[<span class="string">'b1'</span>]))</span><br><span class="line">        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights[<span class="string">'w2'</span>]), self.weights[<span class="string">'b2'</span>])</span><br><span class="line"></span><br><span class="line">        self.cost = <span class="number">0.5</span> * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), <span class="number">2.0</span>))</span><br><span class="line">        self.optimizer = optimizer.minimize(self.cost)</span><br><span class="line"></span><br><span class="line">        init = tf.global_variables_initializer()</span><br><span class="line">        self.sess = tf.Session()</span><br><span class="line">        self.sess.run(init)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span><span class="params">(self)</span>:</span>  <span class="comment"># 初始化权重</span></span><br><span class="line">        all_weights = dict()</span><br><span class="line">        all_weights[<span class="string">'w1'</span>] = tf.Variable(xavier_init(self.n_input, self.n_hidden))</span><br><span class="line">        all_weights[<span class="string">'b1'</span>] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))</span><br><span class="line">        all_weights[<span class="string">'w2'</span>] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype=tf.float32))</span><br><span class="line">        all_weights[<span class="string">'b2'</span>] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32))</span><br><span class="line">        <span class="keyword">return</span> all_weights</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial_fit</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict=&#123;self.x: x, self.scale: self.training_scale&#125;)</span><br><span class="line">        <span class="keyword">return</span> cost</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_total_cost</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.cost, feed_dict=&#123;self.x: x, self.scale: self.training_scale&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.hidden, feed_dict=&#123;self.x: x, self.scale: self.training_scale&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate</span><span class="params">(self, hidden=None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> hidden <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            hidden = np.random.normal(size=self.weights[<span class="string">'b1'</span>])</span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.reconstruction, feed_dict=&#123;self.hidden: hidden&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reconstruct</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.reconstruction, feed_dict=&#123;self.x: x, self.scale: self.training_scale&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getWeights</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.weights[<span class="string">'w1'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getBiases</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sess.run(self.weights[<span class="string">'b1'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">'mnist'</span>, one_hot=<span class="keyword">True</span>)  <span class="comment"># 读取数据</span></span><br><span class="line">    x_train, x_test = standard_scale(mnist.train.images, mnist.test.images) <span class="comment"># 数据标准化</span></span><br><span class="line">    n_samples = int(mnist.train.num_examples) </span><br><span class="line">    training_epoches = <span class="number">20</span></span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    display_step = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化autoencoder</span></span><br><span class="line">    autoencoder = AdditiveGaussianNoiseAutoenvoder(n_input=<span class="number">784</span>, n_hidden=<span class="number">200</span>, transfer_function=tf.nn.relu,</span><br><span class="line">                                                   optimizer=tf.train.AdamOptimizer(learning_rate=<span class="number">0.001</span>), scale=<span class="number">0.02</span>)</span><br><span class="line">    print(n_samples)</span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(training_epoches):</span><br><span class="line">        avg_cost = <span class="number">0.</span></span><br><span class="line">        total_batch = int(n_samples / batch_size)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</span><br><span class="line">            batch_xs = get_random_block_from_data(x_train, batch_size)</span><br><span class="line">            cost = autoencoder.partial_fit(batch_xs)</span><br><span class="line">            avg_cost += cost / n_samples * batch_size</span><br><span class="line">        <span class="keyword">if</span> epoch % display_step == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"Epoch: &#123;:&lt;4&#125; cost= &#123;:.9&#125;"</span>.format(epoch + <span class="number">1</span>, avg_cost))</span><br><span class="line">    print(<span class="string">"Total cost: &#123;&#125;"</span>.format(autoencoder.calc_total_cost(x_test)))</span><br></pre></td></tr></table></figure></div><p class="readmore"><a href="/2017/03/26/2017-03-26-tensorflow-autoencoder/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/03/26/2017-03-26-tensorflow-mnist-softmax/">tensorflow mnist 初体验</a></h1><div class="post-meta">2017-03-26</div><div class="post-content"><p>前提： tensorflow安装好，包括cuda和cudnn</p>
<p>先上代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'./mnist_data/'</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">w = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">y = tf.nn.softmax(tf.matmul(x, w)+b)</span><br><span class="line">y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br><span class="line">tf.global_variables_initializer().run()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    train_step.run(&#123;x: batch_xs, y_:batch_ys&#125;)</span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">print(accuracy.eval(&#123;x:mnist.test.images, y_:mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure></p></div><p class="readmore"><a href="/2017/03/26/2017-03-26-tensorflow-mnist-softmax/">阅读全文</a></p></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yunwangst.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/unsupervised/" style="font-size: 15px;">unsupervised</a> <a href="/tags/mnist/" style="font-size: 15px;">mnist</a> <a href="/tags/cnn/" style="font-size: 15px;">cnn</a> <a href="/tags/dnn/" style="font-size: 15px;">dnn</a> <a href="/tags/lonely/" style="font-size: 15px;">lonely</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/08/2018-05-08-lonely-1/">成为独立开发者</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/13/2017-11-13-it/">go for it</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/09/2017-09-09-DNN-iris/">DNN-iris</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/05/2017-04-05-LSTM/">LSTM</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/02/2017-04-02-tensorflow-cnn/">tensorflow-cnn</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/27/2017-03-27-mnist-single-layer/">mnist单隐层的神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/26/2017-03-26-tensorflow-autoencoder/">tensorflow-autoencoder</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/26/2017-03-26-tensorflow-mnist-softmax/">tensorflow mnist 初体验</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.yunwangst.com" title="中宇云网" target="_blank">中宇云网</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Nic的鱼塘，一条小小的咸鱼.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>